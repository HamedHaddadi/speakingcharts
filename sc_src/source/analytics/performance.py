# ######################################## #
# Tools to compare performance of an asset #
# ######################################## #
import pickle 
import numpy as np 
import pandas as pd 
from os import path, listdir  
from datetime import datetime 
from collections import namedtuple 
from .. utils import keys, tools 
from .. instruments.indices import SP500, Russell3000, Nasdaq


class Performance:
	"""
	generates probability distribution of return, volatility, fundamentals and other metrics
	attributes:
		self.assets = sum of Index objcets: SP500 + Russell3000 + Nasdaq 
	
	Following data can be produced for more graph pbjects 
		return and its histogram 
		volatility and histogram 
		return-volatility
		performance with respect to market
		performance with respect to risk free 
	
	Date ranges are limited:
		Past week
		past 90 days 
		past 180 days 
		past year 
		last two years 
	"""
	current_time = datetime.now().strftime('%Y-%m-%d-%H-%M')
	def __init__(self, universe = None, main_save_path = None):
		self.dates = None
		self.universe = universe 
		self.date_range = self.universe.date_range 
		self.latest_date = self.universe.date_range[1]
		self.main_save_path = tools.make_dir(main_save_path)
		self._generate_dates()
	
	def _generate_dates(self):
		keys = ['LAST_WEEK', 'LAST_MONTH', 'LAST_THREE_MONTHS',
		 	'LAST_SIX_MONTHS', 'LAST_YEAR', 'LAST_TWO_YEARS']
		init_dates = [tools.get_one_week_ago(self.latest_date), tools.get_one_month_ago(self.latest_date), 
						tools.get_six_months_ago(self.latest_date), tools.get_one_year_ago(self.latest_date), 
							tools.get_two_years_ago(self.latest_date)]
		self.dates = {key:(init_date, self.latest_date) for key,init_date in zip(keys, init_dates)}
		
	@property 
	def sample_size(self):
		return len(self.universe.assets)
	
	# #### Compute Methods #### #
	def compute_investment_return_distribution(self, within_dates = None,
				 sampling = 'D', bins = 100):
		"""
		generates return distribution for the entire universe
		"""
		if within_dates is None:
			within_dates = self.universe.date_range 
		investment_return_df = self.universe.compute_investment_returns(within_dates = within_dates, 
					sampling = sampling)
		investment_return_df['Return'] *= 100 
		return_hist, returns = np.histogram(investment_return_df['Return'].values, bins = bins)
		returns = [0.5*(ret[0] + ret[1]) for ret in zip(returns[:-1], returns[1:])]
		return_hist_df = pd.DataFrame(np.c_[np.array(returns)[:,np.newaxis], np.array(return_hist)[:,np.newaxis]], columns = ['Returns', 'Number of Stocks'])
		return_hist_df = return_hist_df[return_hist_df['Number of Stocks'] != 0]
		return investment_return_df, return_hist_df 

	# generating required dataframes in dateranges  
	def compute_and_save_for_dates(self, what = 'return'):
		"""
		computes and saves the dataframes
		"""
		for date_key,date_range in self.dates.items():
			univ_df, hist_df = {'return':self.compute_investment_return_distribution}[what](within_dates = date_range)
			univ_name = what + '_' + date_key + '_UNIVERSE.csv'
			hist_name = what + '_' + date_key + '_HIST.csv'
			univ_df.to_csv(path.join(self.main_save_path, univ_name), sep = ',', header = True, index = False, float_format = '%.4f')
			hist_df.to_csv(path.join(self.main_save_path, hist_name), sep = ',', header = True, index = False, float_format = '%.4f')
				
	@classmethod
	def load_assets_from_indices(cls):
		sp_object = SP500.load_assets()
		ru_object = Russell3000.load_assets()
		nasdaq_object = Nasdaq.load_assets()

		grand_assets_object = sp_object + ru_object + nasdaq_object 
		main_save_path = path.join(keys.DATA_PATH, 'Performance')
		return cls(universe = grand_assets_object, main_save_path = main_save_path)

# #################################################### #
# All distributions and files generated by Performance #
# #################################################### # 
def load_distributions():
	files_path = path.join(keys.LOAD_PATH, 'Performance')
	names = []
	values = []
	for csv_file in listdir(files_path):
		names.append(csv_file.split('.')[0])
		values.append(pd.read_csv(path.join(files_path, csv_file), sep = ',', header = 0))
	Distributions = namedtuple('Distributions', names)
	return Distributions(*values)
